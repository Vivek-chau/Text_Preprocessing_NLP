{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "489c5786-9cb1-4055-8931-5ec929c70742",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df66df19-c61d-44ed-a3ca-99031c01cb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = \"The food is good.The food is bad.Pizza is amazing.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c5edde0-c081-443b-ada5-78433b739721",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11b76cc6-be38-4f9a-9839-506f3cfe06c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the food is good', 'the food is bad', 'pizza is amazing']\n"
     ]
    }
   ],
   "source": [
    "sentences_list  = sentences.split('.')\n",
    "lemmatizer_sentences=[]\n",
    "for sentence in sentences_list:\n",
    "    sentence=re.sub('[^A-Za-z]',' ',sentence)\n",
    "    sentence = sentence.lower()\n",
    "    if sentence: \n",
    "        sentence = sentence.split()\n",
    "        sentence= [lemmatizer.lemmatize(word) for word in sentence]\n",
    "        sentence=' '.join(sentence).strip()\n",
    "        lemmatizer_sentences.append(sentence)\n",
    "print(lemmatizer_sentences)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56991b4e-463e-40f7-8006-6fe7878f49ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'food', 'is', 'good', 'the', 'food', 'is', 'bad', 'pizza', 'is', 'amazing']\n"
     ]
    }
   ],
   "source": [
    "all_words = [word for sentence in lemmatizer_sentences for word in sentence.split()]\n",
    "print(all_words)"
   ]
  },

  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66cfc81c-f564-44d1-8783-6be2be4c9f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['the'], ['food'], ['is'], ['good'], ['the'], ['food'], ['is'], ['bad'], ['pizza'], ['is'], ['amazing']]\n"
     ]
    }
   ],
   "source": [
    "all_words_reshaped = [[word] for word in all_words]\n",
    "print(all_words_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf7abdf5-454b-485a-8fdf-1c5ecb7ba69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and fit OneHotEncoder\n",
    "encoder= OneHotEncoder(sparse_output=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44479dc2-080f-44a5-979f-1e47ac105c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_encoder_words=encoder.fit_transform(all_words_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16a3be8f-fe4a-4dc0-8019-adbe0cc72fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "OneHotEncoder Vocabulary: ['amazing' 'bad' 'food' 'good' 'is' 'pizza' 'the']\n"
     ]
    }
   ],
   "source": [
    "# Get the vocabulary\n",
    "encoded_vocab = encoder.categories_[0]\n",
    "print(\"\\nOneHotEncoder Vocabulary:\", encoded_vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe44999b-c327-4dce-a2ae-543b7f7289fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['x0_amazing' 'x0_bad' 'x0_food' 'x0_good' 'x0_is' 'x0_pizza' 'x0_the']\n",
      "\n",
      "One-Hot Encoded Words (Expanded):\n",
      "Word: 'the' -> One-Hot: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]\n",
      "Word: 'food' -> One-Hot: [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Word: 'is' -> One-Hot: [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]\n",
      "Word: 'good' -> One-Hot: [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]\n",
      "Word: 'bad' -> One-Hot: [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Word: 'pizza' -> One-Hot: [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]\n",
      "Word: 'amazing' -> One-Hot: [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "# Map words to their one-hot encodings\n",
    "word_to_one_hot = {word: one_hot_encoder_words[i] for i, word in enumerate(all_words)}\n",
    "vocabulary = encoder.get_feature_names_out()\n",
    "print(vocabulary)\n",
    "\n",
    "# Print expanded one-hot encoding\n",
    "print(\"\\nOne-Hot Encoded Words (Expanded):\")\n",
    "for word, encoding in word_to_one_hot.items():\n",
    "    encoding_list = encoding.tolist()  # Convert to list for easier reading\n",
    "    print(f\"Word: '{word}' -> One-Hot: {encoding_list}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc52868-03d2-4f66-9c90-749b232cca8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
